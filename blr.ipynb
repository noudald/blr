{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Linear Regression with Pyro\n",
    "\n",
    "The goal of this notebook is to show how to create a bayesian linear regression model for a simple dataset with only one input dimension and one output dimension. All examples I could find immediately go into much more detail on more complex datasets. While for me it's important to understand this simple examples first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyro\n",
    "import pyro.optim\n",
    "import torch\n",
    "\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate toy dataset\n",
    "\n",
    "We generate a toy linear dataset with a bit of noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100\n",
    "\n",
    "X = np.linspace(0, 1, size)\n",
    "Y_true = 2 * X + 1\n",
    "Y = Y_true + np.random.normal(scale=.2, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "ax.plot(X, Y, 'x', label='Sample data')\n",
    "ax.plot(X, Y_true, label='Ground truth', lw=2)\n",
    "ax.legend()\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a regression model\n",
    "\n",
    "We create a regression model with pytorch and train the regression model to fit the sampled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If available use CUDA\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_model = RegressionModel().to(device)\n",
    "\n",
    "print('Random initialized regression model parameters:')\n",
    "for name, param in regression_model.named_parameters():\n",
    "    print(name, param.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(regression_model.parameters(), lr=0.01)\n",
    "num_epochs = 1000\n",
    "\n",
    "x_tensor = torch.tensor(X, dtype=torch.float).unsqueeze(1).to(device)\n",
    "y_tensor = torch.tensor(Y, dtype=torch.float).unsqueeze(1).to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    y_prediction = regression_model(x_tensor)\n",
    "    cur_loss = loss(y_prediction, y_tensor)\n",
    "    optimizer.zero_grad()\n",
    "    cur_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0 or epoch == num_epochs - 1:\n",
    "        print(f'Epoch {epoch}, loss {cur_loss:.4f}')\n",
    "        \n",
    "print('\\nLearned parameters:')\n",
    "for name, param in regression_model.named_parameters():\n",
    "    print(name, param.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "ax.plot(X, Y, 'x', label='Sampled data')\n",
    "ax.plot(X, Y_true, label='Ground truth', lw=2)\n",
    "ax.plot(X, regression_model(x_tensor).detach().cpu().numpy().squeeze(), label='Predicted values')\n",
    "ax.legend()\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Bayesian linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_model(x_data, y_data):\n",
    "    w_prior = pyro.distributions.Normal(\n",
    "        torch.tensor([[0.]]).to(device),\n",
    "        torch.tensor([[1.]]).to(device)).to_event(1)\n",
    "    b_prior = pyro.distributions.Normal(\n",
    "        torch.tensor([[0.]]).to(device),\n",
    "        torch.tensor([[1.]]).to(device)).to_event(1)\n",
    "    \n",
    "    priors = {\n",
    "        'linear.weights': w_prior,\n",
    "        'linear.bias': b_prior\n",
    "    }\n",
    "    \n",
    "    scale = pyro.sample('sigma', pyro.distributions.Uniform(0., 5.))\n",
    "    lifted_module = pyro.random_module('module', regression_model, priors)\n",
    "    lifted_regression_model = lifted_module()\n",
    "    \n",
    "    with pyro.plate('map', len(x_data)):\n",
    "        prediction_mean = lifted_regression_model(x_data).squeeze(1)\n",
    "        if y_data is not None:\n",
    "            pyro.sample(\n",
    "                'obs',\n",
    "                pyro.distributions.Normal(prediction_mean, scale),\n",
    "                obs=y_data.squeeze(1))\n",
    "        else:\n",
    "            pyro.sample('obs', pyro.distributions.Normal(prediction_mean, scale), obs=None)\n",
    "        return prediction_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guide = AutoDiagonalNormal(bayesian_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = pyro.optim.Adam({'lr': 0.01})\n",
    "svi = pyro.infer.SVI(\n",
    "    bayesian_model,\n",
    "    guide,\n",
    "    optimizer,\n",
    "    loss=pyro.infer.Trace_ELBO(),\n",
    "    num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "for epoch in range(3000):\n",
    "    cur_loss = svi.step(x_tensor, y_tensor)\n",
    "    if epoch % 100 == 0 or epoch == num_epochs - 1:\n",
    "        print(f'Epoch {epoch}, loss {cur_loss / len(x_tensor)}')\n",
    "        \n",
    "print('\\nLearned parameters:')\n",
    "for name, param in pyro.get_param_store().items():\n",
    "    print(name, param.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marginals(traces, sites):\n",
    "    samples_and_weights = pyro.infer.EmpiricalMarginal(traces, sites)._get_samples_and_weights()[0]\n",
    "    return samples_and_weights.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_bayesian_model(x_data, y_data):\n",
    "    pyro.sample('prediction', pyro.distributions.Delta(bayesian_model(x_data, y_data)))\n",
    "    \n",
    "posterior = svi.run(x_tensor, y_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_prediction = pyro.infer.TracePredictive(evaluation_bayesian_model, posterior, num_samples=1000)\n",
    "post_prediction = trace_prediction.run(x_tensor, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_marginals = get_marginals(post_prediction, ['prediction', 'obs'])\n",
    "predictions = post_marginals[:, 0, :]\n",
    "observations = post_marginals[:, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "ax.plot(X, Y, 'x', label='Sampled data')\n",
    "ax.plot(X, Y_true, label='Ground truth', lw=2)\n",
    "\n",
    "q05 = np.quantile(predictions, .001, axis=0)\n",
    "q95 = np.quantile(predictions, .999, axis=0)\n",
    "ax.plot(X, predictions.mean(axis=0), label='Bayesian predictions', lw=2)\n",
    "ax.fill_between(X, q05, q95, alpha=0.1)\n",
    "ax.legend()\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "ax.plot(X, Y, 'x', label='Sampled data')\n",
    "ax.plot(X, Y_true, label='Ground truth', lw=2)\n",
    "\n",
    "q05 = np.quantile(observations, .05, axis=0)\n",
    "q95 = np.quantile(observations, .95, axis=0)\n",
    "ax.plot(X, observations.mean(axis=0), label='Bayesian predictions', lw=2)\n",
    "ax.fill_between(X, q05, q95, alpha=0.1)\n",
    "ax.legend()\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
